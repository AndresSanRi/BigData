{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b8188beb12e205e",
   "metadata": {},
   "source": [
    "# Universidad de la Sabana\n",
    "## Big Data Tools\n",
    "### Coterminal - Ingeniería Informática\n",
    "### Prof. Hugo Franco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-09T11:15:02.370189Z",
     "start_time": "2025-08-09T11:15:02.367863Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4e6c9b5204ffc6",
   "metadata": {},
   "source": [
    "- We'll define the paths for the files selected for the analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45af2fde5722778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'result_retrieve_left-and-right_x_50_2016_modified.csv'\n",
    "parquet_path = 'result_retrieve_left-and-right_x_50_2016_modified.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd58310200c452f",
   "metadata": {},
   "source": [
    "- Now, we'll load the two files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0b642ae2c978ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading modified files into new DataFrames...\n",
      "Modified files loaded successfully. Here is a preview of the data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fact_id</th>\n",
       "      <th>year</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>date</th>\n",
       "      <th>otp</th>\n",
       "      <th>trial</th>\n",
       "      <th>group</th>\n",
       "      <th>marker</th>\n",
       "      <th>side</th>\n",
       "      <th>joint</th>\n",
       "      <th>...</th>\n",
       "      <th>protocol</th>\n",
       "      <th>value_x</th>\n",
       "      <th>value_y</th>\n",
       "      <th>value_z</th>\n",
       "      <th>sd_x</th>\n",
       "      <th>sd_y</th>\n",
       "      <th>sd_z</th>\n",
       "      <th>md_x</th>\n",
       "      <th>md_y</th>\n",
       "      <th>md_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14N6HUXKEU0F9OMBGIY|2016-09-27</td>\n",
       "      <td>2016</td>\n",
       "      <td>1T5IA77E6HNZMVG75WMBL35KVPF4D5NUHSGTVV5TUHEV47...</td>\n",
       "      <td>2016-09-27</td>\n",
       "      <td>SIN_OTP</td>\n",
       "      <td>10</td>\n",
       "      <td>POINT</td>\n",
       "      <td>Moments</td>\n",
       "      <td>L</td>\n",
       "      <td>Knee</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>-165.694494</td>\n",
       "      <td>-123.182720</td>\n",
       "      <td>36.022345</td>\n",
       "      <td>0.083000</td>\n",
       "      <td>0.029000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.130000</td>\n",
       "      <td>-0.004700</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14N6HUXKEU0F9OMBGIY|2016-09-27</td>\n",
       "      <td>2016</td>\n",
       "      <td>1T5IA77E6HNZMVG75WMBL35KVPF4D5NUHSGTVV5TUHEV47...</td>\n",
       "      <td>2016-09-27</td>\n",
       "      <td>SIN_OTP</td>\n",
       "      <td>10</td>\n",
       "      <td>POINT</td>\n",
       "      <td>Moments</td>\n",
       "      <td>L</td>\n",
       "      <td>Knee</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>-30.280983</td>\n",
       "      <td>-115.487058</td>\n",
       "      <td>46.915905</td>\n",
       "      <td>0.135116</td>\n",
       "      <td>0.062588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.296398</td>\n",
       "      <td>-0.030691</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14N6HUXKEU0F9OMBGIY|2016-09-27</td>\n",
       "      <td>2016</td>\n",
       "      <td>1T5IA77E6HNZMVG75WMBL35KVPF4D5NUHSGTVV5TUHEV47...</td>\n",
       "      <td>2016-09-27</td>\n",
       "      <td>SIN_OTP</td>\n",
       "      <td>10</td>\n",
       "      <td>POINT</td>\n",
       "      <td>Moments</td>\n",
       "      <td>L</td>\n",
       "      <td>Knee</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>150.967856</td>\n",
       "      <td>-63.342459</td>\n",
       "      <td>45.734985</td>\n",
       "      <td>0.170525</td>\n",
       "      <td>0.072031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.288648</td>\n",
       "      <td>-0.046190</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14N6HUXKEU0F9OMBGIY|2016-09-27</td>\n",
       "      <td>2016</td>\n",
       "      <td>1T5IA77E6HNZMVG75WMBL35KVPF4D5NUHSGTVV5TUHEV47...</td>\n",
       "      <td>2016-09-27</td>\n",
       "      <td>SIN_OTP</td>\n",
       "      <td>10</td>\n",
       "      <td>POINT</td>\n",
       "      <td>Moments</td>\n",
       "      <td>L</td>\n",
       "      <td>Knee</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>341.777878</td>\n",
       "      <td>21.205594</td>\n",
       "      <td>33.002680</td>\n",
       "      <td>0.186234</td>\n",
       "      <td>0.069473</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.185545</td>\n",
       "      <td>-0.048551</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14N6HUXKEU0F9OMBGIY|2016-09-27</td>\n",
       "      <td>2016</td>\n",
       "      <td>1T5IA77E6HNZMVG75WMBL35KVPF4D5NUHSGTVV5TUHEV47...</td>\n",
       "      <td>2016-09-27</td>\n",
       "      <td>SIN_OTP</td>\n",
       "      <td>10</td>\n",
       "      <td>POINT</td>\n",
       "      <td>Moments</td>\n",
       "      <td>L</td>\n",
       "      <td>Knee</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>504.822778</td>\n",
       "      <td>112.502710</td>\n",
       "      <td>14.049575</td>\n",
       "      <td>0.179248</td>\n",
       "      <td>0.067058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.065883</td>\n",
       "      <td>-0.035127</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          fact_id  year  \\\n",
       "0  14N6HUXKEU0F9OMBGIY|2016-09-27  2016   \n",
       "1  14N6HUXKEU0F9OMBGIY|2016-09-27  2016   \n",
       "2  14N6HUXKEU0F9OMBGIY|2016-09-27  2016   \n",
       "3  14N6HUXKEU0F9OMBGIY|2016-09-27  2016   \n",
       "4  14N6HUXKEU0F9OMBGIY|2016-09-27  2016   \n",
       "\n",
       "                                          subject_id        date      otp  \\\n",
       "0  1T5IA77E6HNZMVG75WMBL35KVPF4D5NUHSGTVV5TUHEV47...  2016-09-27  SIN_OTP   \n",
       "1  1T5IA77E6HNZMVG75WMBL35KVPF4D5NUHSGTVV5TUHEV47...  2016-09-27  SIN_OTP   \n",
       "2  1T5IA77E6HNZMVG75WMBL35KVPF4D5NUHSGTVV5TUHEV47...  2016-09-27  SIN_OTP   \n",
       "3  1T5IA77E6HNZMVG75WMBL35KVPF4D5NUHSGTVV5TUHEV47...  2016-09-27  SIN_OTP   \n",
       "4  1T5IA77E6HNZMVG75WMBL35KVPF4D5NUHSGTVV5TUHEV47...  2016-09-27  SIN_OTP   \n",
       "\n",
       "   trial  group   marker side joint  ... protocol     value_x     value_y  \\\n",
       "0     10  POINT  Moments    L  Knee  ...        M -165.694494 -123.182720   \n",
       "1     10  POINT  Moments    L  Knee  ...        M  -30.280983 -115.487058   \n",
       "2     10  POINT  Moments    L  Knee  ...        M  150.967856  -63.342459   \n",
       "3     10  POINT  Moments    L  Knee  ...        M  341.777878   21.205594   \n",
       "4     10  POINT  Moments    L  Knee  ...        M  504.822778  112.502710   \n",
       "\n",
       "     value_z      sd_x      sd_y  sd_z      md_x      md_y  md_z  \n",
       "0  36.022345  0.083000  0.029000   0.0 -0.130000 -0.004700   0.0  \n",
       "1  46.915905  0.135116  0.062588   0.0 -0.296398 -0.030691   0.0  \n",
       "2  45.734985  0.170525  0.072031   0.0 -0.288648 -0.046190   0.0  \n",
       "3  33.002680  0.186234  0.069473   0.0 -0.185545 -0.048551   0.0  \n",
       "4  14.049575  0.179248  0.067058   0.0 -0.065883 -0.035127   0.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Load the modified files ---\n",
    "print(\"Loading modified files into new DataFrames...\")\n",
    "df_csv = pd.read_csv(csv_path)\n",
    "df_parquet = pd.read_parquet(parquet_path)\n",
    "\n",
    "print(\"Modified files loaded successfully. Here is a preview of the data:\")\n",
    "display(df_csv.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195aaaa0f68e899f",
   "metadata": {},
   "source": [
    "- Let's compare the disk size and the shape (rows, columns) of the two file formats. You'll notice that Parquet is significantly more efficient for storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5db34b6aad778a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- File and DataFrame Comparison ---\n",
      "\n",
      "CSV File:\n",
      "  - File Path: result_retrieve_left-and-right_x_50_2016_modified.csv\n",
      "  - Size on disk: 5118.94 KB\n",
      "  - Shape: 19800 rows, 22 columns\n",
      "\n",
      "Parquet File:\n",
      "  - File Path: result_retrieve_left-and-right_x_50_2016_modified.parquet\n",
      "  - Size on disk: 234.40 KB\n",
      "  - Shape: 8800 rows, 22 columns\n",
      "\n",
      "Note: The Parquet file is 95.42% smaller than the CSV file.\n"
     ]
    }
   ],
   "source": [
    "# --- Compare file size and DataFrame shape ---\n",
    "\n",
    "# Get file sizes\n",
    "csv_size_bytes = os.path.getsize(csv_path)\n",
    "parquet_size_bytes = os.path.getsize(parquet_path)\n",
    "\n",
    "# Get DataFrame shapes\n",
    "csv_rows, csv_cols = df_csv.shape\n",
    "parquet_rows, parquet_cols = df_parquet.shape\n",
    "\n",
    "# Print comparison\n",
    "print(\"--- File and DataFrame Comparison ---\")\n",
    "print(\"\\nCSV File:\")\n",
    "print(f\"  - File Path: {csv_path}\")\n",
    "print(f\"  - Size on disk: {csv_size_bytes / 1024:.2f} KB\")\n",
    "print(f\"  - Shape: {csv_rows} rows, {csv_cols} columns\")\n",
    "\n",
    "print(\"\\nParquet File:\")\n",
    "print(f\"  - File Path: {parquet_path}\")\n",
    "print(f\"  - Size on disk: {parquet_size_bytes / 1024:.2f} KB\")\n",
    "print(f\"  - Shape: {parquet_rows} rows, {parquet_cols} columns\")\n",
    "\n",
    "# Highlight the size difference\n",
    "size_difference = (csv_size_bytes - parquet_size_bytes) / csv_size_bytes * 100\n",
    "print(f\"\\nNote: The Parquet file is {size_difference:.2f}% smaller than the CSV file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f82bffe29c0f05",
   "metadata": {},
   "source": [
    "- The .describe() method provides a powerful statistical summary of the data. Using include='all' gives us statistics for both numerical and text-based columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dea515fb127a6f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Statistical Description ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8800 entries, 0 to 8799\n",
      "Data columns (total 22 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   fact_id     8800 non-null   object \n",
      " 1   year        8800 non-null   object \n",
      " 2   subject_id  8800 non-null   object \n",
      " 3   date        8800 non-null   object \n",
      " 4   otp         8800 non-null   object \n",
      " 5   trial       8800 non-null   object \n",
      " 6   group       8800 non-null   object \n",
      " 7   marker      8800 non-null   object \n",
      " 8   side        8800 non-null   object \n",
      " 9   joint       8800 non-null   object \n",
      " 10  variable    8800 non-null   object \n",
      " 11  units       8800 non-null   object \n",
      " 12  protocol    8800 non-null   object \n",
      " 13  value_x     7216 non-null   float64\n",
      " 14  value_y     7216 non-null   float64\n",
      " 15  value_z     7216 non-null   float64\n",
      " 16  sd_x        8800 non-null   float64\n",
      " 17  sd_y        8800 non-null   float64\n",
      " 18  sd_z        8800 non-null   float64\n",
      " 19  md_x        8800 non-null   float64\n",
      " 20  md_y        8800 non-null   float64\n",
      " 21  md_z        8800 non-null   float64\n",
      "dtypes: float64(9), object(13)\n",
      "memory usage: 1.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fact_id</th>\n",
       "      <th>year</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>date</th>\n",
       "      <th>otp</th>\n",
       "      <th>trial</th>\n",
       "      <th>group</th>\n",
       "      <th>marker</th>\n",
       "      <th>side</th>\n",
       "      <th>joint</th>\n",
       "      <th>...</th>\n",
       "      <th>protocol</th>\n",
       "      <th>value_x</th>\n",
       "      <th>value_y</th>\n",
       "      <th>value_z</th>\n",
       "      <th>sd_x</th>\n",
       "      <th>sd_y</th>\n",
       "      <th>sd_z</th>\n",
       "      <th>md_x</th>\n",
       "      <th>md_y</th>\n",
       "      <th>md_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8800</td>\n",
       "      <td>8800</td>\n",
       "      <td>8800</td>\n",
       "      <td>8800</td>\n",
       "      <td>8800</td>\n",
       "      <td>8800</td>\n",
       "      <td>8800</td>\n",
       "      <td>8800</td>\n",
       "      <td>8800</td>\n",
       "      <td>8800</td>\n",
       "      <td>...</td>\n",
       "      <td>8800</td>\n",
       "      <td>7216.000000</td>\n",
       "      <td>7216.000000</td>\n",
       "      <td>7216.000000</td>\n",
       "      <td>8800.000000</td>\n",
       "      <td>8800.000000</td>\n",
       "      <td>8800.000000</td>\n",
       "      <td>8800.000000</td>\n",
       "      <td>8800.000000</td>\n",
       "      <td>8800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>16JZX591JS12OA71FJG|2016-10-06</td>\n",
       "      <td>2016</td>\n",
       "      <td>1KUCI5Q2K8BYL2AN2Y53DJ2175OOJB5UN1GZWWK8UZEUMX...</td>\n",
       "      <td>2016-10-06</td>\n",
       "      <td>SIN_OTP</td>\n",
       "      <td>2</td>\n",
       "      <td>POINT</td>\n",
       "      <td>Angles</td>\n",
       "      <td>R</td>\n",
       "      <td>Hip</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>200</td>\n",
       "      <td>8800</td>\n",
       "      <td>6600</td>\n",
       "      <td>6600</td>\n",
       "      <td>8800</td>\n",
       "      <td>4400</td>\n",
       "      <td>8800</td>\n",
       "      <td>4000</td>\n",
       "      <td>4400</td>\n",
       "      <td>2400</td>\n",
       "      <td>...</td>\n",
       "      <td>8800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.432984</td>\n",
       "      <td>15.916871</td>\n",
       "      <td>-3.227927</td>\n",
       "      <td>1.973306</td>\n",
       "      <td>0.803216</td>\n",
       "      <td>1.772090</td>\n",
       "      <td>3.869123</td>\n",
       "      <td>0.029573</td>\n",
       "      <td>-0.736129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.666356</td>\n",
       "      <td>85.375134</td>\n",
       "      <td>27.399121</td>\n",
       "      <td>2.648440</td>\n",
       "      <td>1.446461</td>\n",
       "      <td>3.297644</td>\n",
       "      <td>9.737355</td>\n",
       "      <td>1.260679</td>\n",
       "      <td>3.560550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-603.222227</td>\n",
       "      <td>-404.164356</td>\n",
       "      <td>-168.739931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-19.822896</td>\n",
       "      <td>-7.105825</td>\n",
       "      <td>-17.840089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.138910</td>\n",
       "      <td>-18.647917</td>\n",
       "      <td>0.002103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.904576</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.132565</td>\n",
       "      <td>0.213006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.310656</td>\n",
       "      <td>3.409325</td>\n",
       "      <td>7.854257</td>\n",
       "      <td>4.939620</td>\n",
       "      <td>1.970042</td>\n",
       "      <td>2.091543</td>\n",
       "      <td>2.784633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1500.743634</td>\n",
       "      <td>866.649194</td>\n",
       "      <td>200.863082</td>\n",
       "      <td>9.514070</td>\n",
       "      <td>8.076213</td>\n",
       "      <td>10.415591</td>\n",
       "      <td>59.106221</td>\n",
       "      <td>5.220230</td>\n",
       "      <td>4.020000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               fact_id  year  \\\n",
       "count                             8800  8800   \n",
       "unique                              66     1   \n",
       "top     16JZX591JS12OA71FJG|2016-10-06  2016   \n",
       "freq                               200  8800   \n",
       "mean                               NaN   NaN   \n",
       "std                                NaN   NaN   \n",
       "min                                NaN   NaN   \n",
       "25%                                NaN   NaN   \n",
       "50%                                NaN   NaN   \n",
       "75%                                NaN   NaN   \n",
       "max                                NaN   NaN   \n",
       "\n",
       "                                               subject_id        date  \\\n",
       "count                                                8800        8800   \n",
       "unique                                                  2           2   \n",
       "top     1KUCI5Q2K8BYL2AN2Y53DJ2175OOJB5UN1GZWWK8UZEUMX...  2016-10-06   \n",
       "freq                                                 6600        6600   \n",
       "mean                                                  NaN         NaN   \n",
       "std                                                   NaN         NaN   \n",
       "min                                                   NaN         NaN   \n",
       "25%                                                   NaN         NaN   \n",
       "50%                                                   NaN         NaN   \n",
       "75%                                                   NaN         NaN   \n",
       "max                                                   NaN         NaN   \n",
       "\n",
       "            otp trial  group  marker  side joint  ... protocol      value_x  \\\n",
       "count      8800  8800   8800    8800  8800  8800  ...     8800  7216.000000   \n",
       "unique        1     3      1       3     2     5  ...        1          NaN   \n",
       "top     SIN_OTP     2  POINT  Angles     R   Hip  ...        M          NaN   \n",
       "freq       8800  4400   8800    4000  4400  2400  ...     8800          NaN   \n",
       "mean        NaN   NaN    NaN     NaN   NaN   NaN  ...      NaN    45.432984   \n",
       "std         NaN   NaN    NaN     NaN   NaN   NaN  ...      NaN   180.666356   \n",
       "min         NaN   NaN    NaN     NaN   NaN   NaN  ...      NaN  -603.222227   \n",
       "25%         NaN   NaN    NaN     NaN   NaN   NaN  ...      NaN     0.000000   \n",
       "50%         NaN   NaN    NaN     NaN   NaN   NaN  ...      NaN     8.904576   \n",
       "75%         NaN   NaN    NaN     NaN   NaN   NaN  ...      NaN    34.310656   \n",
       "max         NaN   NaN    NaN     NaN   NaN   NaN  ...      NaN  1500.743634   \n",
       "\n",
       "            value_y      value_z         sd_x         sd_y         sd_z  \\\n",
       "count   7216.000000  7216.000000  8800.000000  8800.000000  8800.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      15.916871    -3.227927     1.973306     0.803216     1.772090   \n",
       "std       85.375134    27.399121     2.648440     1.446461     3.297644   \n",
       "min     -404.164356  -168.739931     0.000000     0.000000     0.000000   \n",
       "25%       -4.138910   -18.647917     0.002103     0.000000     0.000000   \n",
       "50%        0.000000    -0.132565     0.213006     0.000000     0.000000   \n",
       "75%        3.409325     7.854257     4.939620     1.970042     2.091543   \n",
       "max      866.649194   200.863082     9.514070     8.076213    10.415591   \n",
       "\n",
       "               md_x         md_y         md_z  \n",
       "count   8800.000000  8800.000000  8800.000000  \n",
       "unique          NaN          NaN          NaN  \n",
       "top             NaN          NaN          NaN  \n",
       "freq            NaN          NaN          NaN  \n",
       "mean       3.869123     0.029573    -0.736129  \n",
       "std        9.737355     1.260679     3.560550  \n",
       "min      -19.822896    -7.105825   -17.840089  \n",
       "25%        0.000000     0.000000     0.000000  \n",
       "50%        0.002816     0.000000     0.000000  \n",
       "75%        2.784633     0.000000     0.000000  \n",
       "max       59.106221     5.220230     4.020000  \n",
       "\n",
       "[11 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Obtain a statistical description of the DataFrame ---\n",
    "# (We only need to run this on one DataFrame, as they contain identical data)\n",
    "\n",
    "print(\"--- Statistical Description ---\")\n",
    "df_parquet.info()\n",
    "display(df_parquet.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3212268b29422cd",
   "metadata": {},
   "source": [
    "This is the core analysis step. We group the data by the specified categories and calculate the average value_x, value_y, and value_z for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2551187886f1f4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouping by ['fact_id', 'side', 'joint', 'variable'] and calculating the mean of ['value_x', 'value_y', 'value_z']...\n",
      "\n",
      "Preview of the final data to be loaded:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fact_id</th>\n",
       "      <th>side</th>\n",
       "      <th>joint</th>\n",
       "      <th>variable</th>\n",
       "      <th>avg_x</th>\n",
       "      <th>avg_y</th>\n",
       "      <th>avg_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16JZX591JS12OA71FJG|2016-10-06</td>\n",
       "      <td>R</td>\n",
       "      <td>Thorax</td>\n",
       "      <td>ThoraxAngles</td>\n",
       "      <td>6.180246</td>\n",
       "      <td>-1.023905e+00</td>\n",
       "      <td>-27.015106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1CT4N2QMHHMQ65OLACQ|2016-09-16</td>\n",
       "      <td>R</td>\n",
       "      <td>Hip</td>\n",
       "      <td>HipMoment</td>\n",
       "      <td>-9.207832</td>\n",
       "      <td>-1.036203e+01</td>\n",
       "      <td>0.157902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1IS23X3HH1TI5P28Y39|2016-09-16</td>\n",
       "      <td>L</td>\n",
       "      <td>Hip</td>\n",
       "      <td>HipMoment</td>\n",
       "      <td>-40.811779</td>\n",
       "      <td>-7.442207e+01</td>\n",
       "      <td>22.114508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1NB0OCWZZK52RI8FJLP|2016-10-06</td>\n",
       "      <td>L</td>\n",
       "      <td>Ankle</td>\n",
       "      <td>AnkleMoment</td>\n",
       "      <td>-11.118538</td>\n",
       "      <td>-1.254974e-16</td>\n",
       "      <td>3.957033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1SHOXV29S3GK4CT68B3|2016-09-16</td>\n",
       "      <td>L</td>\n",
       "      <td>Ankle</td>\n",
       "      <td>AnklePower</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.002611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          fact_id side   joint      variable      avg_x  \\\n",
       "0  16JZX591JS12OA71FJG|2016-10-06    R  Thorax  ThoraxAngles   6.180246   \n",
       "1  1CT4N2QMHHMQ65OLACQ|2016-09-16    R     Hip     HipMoment  -9.207832   \n",
       "2  1IS23X3HH1TI5P28Y39|2016-09-16    L     Hip     HipMoment -40.811779   \n",
       "3  1NB0OCWZZK52RI8FJLP|2016-10-06    L   Ankle   AnkleMoment -11.118538   \n",
       "4  1SHOXV29S3GK4CT68B3|2016-09-16    L   Ankle    AnklePower   0.000000   \n",
       "\n",
       "          avg_y      avg_z  \n",
       "0 -1.023905e+00 -27.015106  \n",
       "1 -1.036203e+01   0.157902  \n",
       "2 -7.442207e+01  22.114508  \n",
       "3 -1.254974e-16   3.957033  \n",
       "4  0.000000e+00   0.002611  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Create average values for x, y, and z columns ---\n",
    "\n",
    "# Define the columns to group by and the columns to aggregate\n",
    "grouping_cols = ['fact_id', 'side', 'joint', 'variable']\n",
    "value_cols = ['value_x', 'value_y', 'value_z']\n",
    "\n",
    "print(f\"Grouping by {grouping_cols} and calculating the mean of {value_cols}...\")\n",
    "\n",
    "# Perform the groupby and aggregation.\n",
    "# .reset_index() converts the grouped columns back into regular columns.\n",
    "df_agg = df_parquet.groupby(grouping_cols)[value_cols].mean().reset_index()\n",
    "\n",
    "# Rename columns for clarity in the database\n",
    "df_agg.rename(columns={\n",
    "    'value_x': 'avg_x',\n",
    "    'value_y': 'avg_y',\n",
    "    'value_z': 'avg_z'\n",
    "}, inplace=True)\n",
    "\n",
    "print(\"\\nPreview of the final data to be loaded:\")\n",
    "display(df_agg.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ea34bf",
   "metadata": {},
   "source": [
    "# Taller\n",
    "- Andrés Felipe Sanchez Rincon\n",
    "- Ricardo Andrés Cortés Coronell\n",
    "- Carlos Andrés Zuluaga Mora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db7ec0d9f9a0021",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Handling Missing Data:\n",
    "\n",
    "•The value_x, value_y, and value_z columns have some missing entries. First, calculate and print the total number of missing values for each of these three columns.\n",
    "\n",
    "•Create a new, cleaned DataFrame by dropping all rows that have missing values in any of those three columns (value_x, value_y, or value_z).\n",
    "\n",
    "•Verify your work by checking for missing values again in the new DataFrame.3.Data Filtering and Subsetting\n",
    "\n",
    "•From your cleaned DataFrame (from Question 2), remove the columns sd_x, sd_y, sd_z, md_x, md_y, and md_z, as they are not needed for this analysis.\n",
    "\n",
    "•Create a new DataFrame that contains only the data for the 'Hip' joint. How many rows remain in this new 'Hip' DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "846ee6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores faltantes iniciales:\n",
      "value_x    1584\n",
      "value_y    1584\n",
      "value_z    1584\n",
      "dtype: int64\n",
      "\n",
      "Valores faltantes después de limpiar:\n",
      "value_x    0\n",
      "value_y    0\n",
      "value_z    0\n",
      "dtype: int64\n",
      "\n",
      "Número de filas para la articulación 'Hip': 4872\n"
     ]
    }
   ],
   "source": [
    "# Cargar el CSV\n",
    "df = pd.read_csv(\"result_retrieve_left-and-right_x_50_2016_modified.csv\")\n",
    "\n",
    "# 1. Calcular valores faltantes\n",
    "missing_counts = df[['value_x', 'value_y', 'value_z']].isnull().sum()\n",
    "print(\"Valores faltantes iniciales:\")\n",
    "print(missing_counts)\n",
    "\n",
    "# 2. Limpiar DataFrame eliminando filas con valores faltantes en esas columnas\n",
    "df_cleaned = df.dropna(subset=['value_x', 'value_y', 'value_z'])\n",
    "\n",
    "# 3. Verificar que ya no hay valores faltantes\n",
    "missing_counts_after = df_cleaned[['value_x', 'value_y', 'value_z']].isnull().sum()\n",
    "print(\"\\nValores faltantes después de limpiar:\")\n",
    "print(missing_counts_after)\n",
    "\n",
    "# 4. Eliminar columnas no necesarias\n",
    "df_cleaned_reduced = df_cleaned.drop(columns=['sd_x', 'sd_y', 'sd_z', 'md_x', 'md_y', 'md_z'])\n",
    "\n",
    "# 5. Filtrar solo la articulación 'Hip'\n",
    "df_hip = df_cleaned_reduced[df_cleaned_reduced['joint'] == 'Hip']\n",
    "print(f\"\\nNúmero de filas para la articulación 'Hip': {len(df_hip)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e87827",
   "metadata": {},
   "source": [
    "## 2. File Format Comparison:\n",
    "\n",
    "•Take the final 'Hip' DataFrame from Question 3 and save it to two new files: hip_data.csv and hip_data.parquet.\n",
    "\n",
    "•Using Python's os library, get the size of each file on disk.\n",
    "\n",
    "•Calculate and print the percentage difference in size, showing how much smaller the Parquet file is compared to the CSV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48f222bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del archivo CSV:  907.23 KB\n",
      "Tamaño del archivo Parquet:  115.16 KB\n",
      "El archivo Parquet es 87.31% más pequeño que el archivo CSV.\n"
     ]
    }
   ],
   "source": [
    "# 1. Se definen los nombres de los archivos de salida (output)\n",
    "csv_output_path = 'hip_data.csv'\n",
    "parquet_output_path = 'hip_data.parquet'\n",
    "\n",
    "# 2. Se guarda el DataFrame 'Hip' en un archivo CSV\n",
    "df_hip.to_csv(csv_output_path, index=False)\n",
    "\n",
    "# 3. Se guarda el DataFrame 'Hip' en un archivo Parquet\n",
    "df_hip.to_parquet(parquet_output_path, index=False)\n",
    "\n",
    "# 4. Se extrae el tamaño de cada archivo en el disco\n",
    "csv_output_size = os.path.getsize(csv_output_path)\n",
    "parquet_output_size = os.path.getsize(parquet_output_path)\n",
    "\n",
    "# 5. Se calcula la diferencia de tamaño en terminos de porcentaje\n",
    "csv_parquet_difference = ((csv_output_size - parquet_output_size) / csv_output_size) * 100\n",
    "\n",
    "# 6. Se imprimen los resultados\n",
    "print(f\"Tamaño del archivo CSV: {csv_output_size /1024: .2f} KB\")\n",
    "print(f\"Tamaño del archivo Parquet: {parquet_output_size /1024: .2f} KB\")\n",
    "print(f\"El archivo Parquet es {csv_parquet_difference:.2f}% más pequeño que el archivo CSV.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5156098f",
   "metadata": {},
   "source": [
    "## 3. Advanced Pandas Aggregation:\n",
    "\n",
    "•Using the full cleaned DataFrame (from Question 2, before filtering for the 'Hip' joint), group the data by side and variable.\n",
    "\n",
    "•For each group, calculate the standard deviation (std) of value_x, value_y, and value_z.\n",
    "\n",
    "•Display the resulting aggregated DataFrame. Which variable shows the highest standard deviation for value_x on the 'L' (Left) side?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a0add35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Frame agregado:\n",
      "   side      variable     value_x     value_y    value_z\n",
      "0     L   AnkleAngles    4.407460   -0.345501   8.667674\n",
      "1     L   AnkleMoment  301.626508    1.470049   5.887500\n",
      "2     L    AnklePower    0.000000    0.000000   0.107209\n",
      "3     L     HipAngles   30.022897    1.393280 -13.266072\n",
      "4     L     HipMoment   48.738425  131.486126  -4.757400\n",
      "5     L      HipPower    0.000000    0.000000   0.178581\n",
      "6     L    KneeAngles   35.697567  -11.139698  -4.929386\n",
      "7     L    KneeMoment   19.166441   20.644291  -1.032082\n",
      "8     L     KneePower    0.000000    0.000000  -0.130541\n",
      "9     L  PelvisAngles   17.321727    2.098644   7.690480\n",
      "10    L  ThoraxAngles    4.521648    1.940969   9.137380\n",
      "11    R   AnkleAngles    6.417338    2.302416  -5.006971\n",
      "12    R   AnkleMoment  259.397463   29.467339  26.658447\n",
      "13    R    AnklePower    0.000000    0.000000   0.009300\n",
      "14    R     HipAngles   30.841807    4.219198  -1.390950\n",
      "15    R     HipMoment   49.477142  216.122922  -7.312448\n",
      "16    R      HipPower    0.000000    0.000000   0.212409\n",
      "17    R    KneeAngles   38.274022   -6.221945   6.046176\n",
      "18    R    KneeMoment  -11.313786   80.651483  30.090551\n",
      "19    R     KneePower    0.000000    0.000000  -0.064153\n",
      "20    R  PelvisAngles   17.267386   -1.695587  -7.672001\n",
      "21    R  ThoraxAngles    5.020103   -1.690672  -9.139630\n",
      "\n",
      "La desviación estándar de X es:\n",
      " side\n",
      "L    87.678215\n",
      "R    76.440955\n",
      "Name: value_x, dtype: float64\n",
      "La desviación estándar de Y es:\n",
      " side\n",
      "L    39.839856\n",
      "R    66.825207\n",
      "Name: value_y, dtype: float64\n",
      "La desviación estándar de Z es:\n",
      " side\n",
      "L     6.865026\n",
      "R    13.341569\n",
      "Name: value_z, dtype: float64\n",
      "\n",
      "La variable que muestra la mayor desviación estándar en L es: X\n"
     ]
    }
   ],
   "source": [
    "# 1. Agrupar por 'Side' y 'Variable'\n",
    "df_grouped = df.groupby(['side', 'variable'])[['value_x', 'value_y', 'value_z']].mean().reset_index()\n",
    "\n",
    "# Mostrar Data Frame agregado\n",
    "print(f\"Data Frame agregado:\\n{df_grouped}\\n\")\n",
    "\n",
    "# 2. Calcular la desviación estándar para cada variable\n",
    "x_std = df_grouped.groupby('side')['value_x'].std()\n",
    "y_std = df_grouped.groupby('side')['value_y'].std()\n",
    "z_std = df_grouped.groupby('side')['value_z'].std()\n",
    "\n",
    "print(f\"La desviación estándar de X es:\\n {x_std}\")\n",
    "print(f\"La desviación estándar de Y es:\\n {y_std}\")\n",
    "print(f\"La desviación estándar de Z es:\\n {z_std}\")\n",
    "\n",
    "# 3. ¿Qué variable muestra la mayor desviación de estándar en L?\n",
    "print()\n",
    "max_std = max(x_std['L'], y_std['L'], z_std['L'])\n",
    "if max_std == x_std['L']:\n",
    "    print(\"La variable que muestra la mayor desviación estándar en L es: X\")\n",
    "elif max_std == y_std['L']:\n",
    "    print(\"La variable que muestra la mayor desviación estándar en L es: Y\")\n",
    "else:\n",
    "    print(\"La variable que muestra la mayor desviación estándar en L es: Z\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57150e95",
   "metadata": {},
   "source": [
    "6. Finding a Maximum Value:\n",
    "\n",
    "•Using the full cleaned DataFrame, find the fact_id that corresponds to the single highest value_y measurement recorded in the entire dataset. (Hint: You might find the .idxmax() method useful)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "13e56d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El fact_id con el valor más alto en value_y (867.4643615722656) es: ZRCB7GWUHEJRQF8CBG|2016-09-27\n"
     ]
    }
   ],
   "source": [
    "# Buscar fact_id correspondiente al value_y más alto\n",
    "highest_fact_id = df.loc[df['value_y'].idxmax(), 'fact_id']\n",
    "print(f\"El fact_id con el valor más alto en value_y ({df['value_y'].max()}) es: {highest_fact_id}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
